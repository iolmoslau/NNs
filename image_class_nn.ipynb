{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2c1800-d2bc-492e-980a-c113336756bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tr\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff4c47-cf8d-45c5-8804-cea6340775cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_Net:\n",
    "    \"\"\"\n",
    "     Architecture:\n",
    "      input_len -> widths[0] -> widths[1] -> ... -> widths[depth-1] -> output_len\n",
    "\n",
    "    Parameters stored after initialize():\n",
    "      self.W: list of weight matrices\n",
    "      self.b: list of bias vectors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_len: int, output_len: int, depth: int, widths: np.ndarray):\n",
    "        self.input_len = int(input_len)\n",
    "        self.output_len = int(output_len)\n",
    "        self.depth = int(depth)\n",
    "        self.widths = np.array(widths, dtype=int)\n",
    "\n",
    "        # --- Assertions ---\n",
    "        assert self.input_len > 0, \"input_len must be a positive integer.\"\n",
    "        assert self.output_len > 0, \"output_len must be a positive integer.\"\n",
    "        assert self.depth >= 0, \"depth must be >= 0 (number of hidden layers).\"\n",
    "\n",
    "        assert self.widths.ndim == 1, \"widths must be a 1D array-like.\"\n",
    "        assert len(self.widths) == self.depth, (\n",
    "            f\"depth={self.depth} but len(widths)={len(self.widths)}. \"\n",
    "            \"Provide one width per hidden layer.\"\n",
    "        )\n",
    "        assert np.all(self.widths > 0), \"All entries of widths must be positive integers.\"\n",
    "\n",
    "        # Parameter containers (filled by initialize)\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def initialize(self, seed: int | None = None, scale: float = 0.01):\n",
    "        \"\"\"\n",
    "        Create weight matrices and bias vectors.\n",
    "\n",
    "        Weights:\n",
    "          W[0] shape: (widths[0], input_len)\n",
    "          W[i] shape: (widths[i], widths[i-1]) for i=1..depth-1\n",
    "          W_out shape: (output_len, widths[depth-1]) if depth>0 else (output_len, input_len)\n",
    "\n",
    "        Biases:\n",
    "          b[i] shape: (widths[i],)\n",
    "          b_out shape: (output_len,)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (W, b) where each is a list of numpy arrays.\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        W = []\n",
    "        b = []\n",
    "\n",
    "        if self.depth == 0:\n",
    "            # No hidden layers: input -> output directly\n",
    "            W.append(scale * rng.standard_normal((self.output_len, self.input_len)))\n",
    "            b.append(np.zeros((self.output_len,), dtype=float))\n",
    "        else:\n",
    "            # Input -> first hidden\n",
    "            W.append(scale * rng.standard_normal((self.widths[0], self.input_len)))\n",
    "            b.append(np.zeros((self.widths[0],), dtype=float))\n",
    "\n",
    "            # Hidden -> hidden\n",
    "            for i in range(1, self.depth):\n",
    "                W.append(scale * rng.standard_normal((self.widths[i], self.widths[i - 1])))\n",
    "                b.append(np.zeros((self.widths[i],), dtype=float))\n",
    "\n",
    "            # Last hidden -> output\n",
    "            W.append(scale * rng.standard_normal((self.output_len, self.widths[-1])))\n",
    "            b.append(np.zeros((self.output_len,), dtype=float))\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        return \n",
    "\n",
    "    def forward_pass(self, x, activation=\"relu\"):\n",
    "    \"\"\"\n",
    "    Forward pass through the network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        Shape (input_len,) for a single sample or (N, input_len) for a batch.\n",
    "    activation : {\"relu\",\"tanh\",\"sigmoid\",\"identity\"} or callable\n",
    "        Activation applied on hidden layers only. Output layer is linear.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : np.ndarray\n",
    "        Shape (output_len,) for single sample or (N, output_len) for batch.\n",
    "    \"\"\"\n",
    "    assert self.W is not None and self.b is not None and len(self.W) > 0, \\\n",
    "        \"Call initialize() before forward_pass().\"\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    assert x.shape[-1] == self.input_len, \\\n",
    "        f\"Expected last dim {self.input_len}, got {x.shape[-1]}.\"\n",
    "\n",
    "    # Choose activation\n",
    "    if callable(activation):\n",
    "        act = activation\n",
    "    else:\n",
    "        a = str(activation).lower()\n",
    "        if a == \"relu\":\n",
    "            act = lambda z: np.maximum(0.0, z)\n",
    "        elif a == \"tanh\":\n",
    "            act = np.tanh\n",
    "        elif a == \"sigmoid\":\n",
    "            act = lambda z: 1.0 / (1.0 + np.exp(-z))\n",
    "        elif a in (\"identity\", \"linear\", \"none\"):\n",
    "            act = lambda z: z\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation}\")\n",
    "\n",
    "    h = x\n",
    "    # Hidden layers: affine + activation\n",
    "    for W, b in zip(self.W[:-1], self.b[:-1]):\n",
    "        h = h @ W.T + b\n",
    "        h = act(h)\n",
    "\n",
    "    # Output layer: affine only\n",
    "    W_out, b_out = self.W[-1], self.b[-1]\n",
    "    y = h @ W_out.T + b_out\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
